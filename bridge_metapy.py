import metapy
from base_helpers import *
import math

# Compute IDF weighting
def idf(term_id, idx_train):
    return math.log((idx_train.num_docs() + 1)/(idx_train.doc_freq(term_id)),2)


# Custom BM25 ranker.
# document: tuple in the form (doc_id_test, analyzed_doc)
# doc_id_test: document id in the test set
# analyzed_doc: a dict generated by metapy analyzer through fitlering and tokenization in the form {term: freq}
# analyzed_query: query that has been filtered and tokenized into a dict of {term: freq}
# idx_test: inverted index for the test set
# idx_train: inverted index for the training set
# k: TF weighting parameter, between 0 and inf.
# b: Length normalization influence, between 0 and 1.
def BM25_score(document, analyzed_query, idx_test, idx_train, k, b):
    rank_score = 0
    # Current document length
    doc_length = 0
    analyzed_doc = document[1]
    for term in analyzed_doc:
        doc_length += analyzed_doc[term]

    # Compute rank score by summing over all shared terms.
    for term in analyzed_query:
        # Check if doc also contains term first. Otherwise skip.
        if (term not in analyzed_doc):
            continue

        # Term count for the query
        c_w_q = analyzed_query[term]
        print(term + " freq in query = " + str(c_w_q))
        # Term id in the test set containing the document
        term_id_test = idx_test.get_term_id(term)
        # Term id in the training set
        term_id_train = idx_train.get_term_id(term)
        # Document test set id.
        doc_id_test = document[0]
        # Compute average document length in the training set after adding current doc to it.
        avdl = (idx_train.avg_doc_length()*idx_train.num_docs() + doc_length)/(idx_train.num_docs() + 1)
        c_w_d = idx_test.term_freq(term_id_test, doc_id_test)
        print(term + " freq in doc = " + str(c_w_d))
        rank_score += c_w_q*c_w_d*(k+1)/(c_w_d + k*(1 - b + b*doc_length/avdl))*idf(term_id_train,idx_train)

    return rank_score


# Given a list of gains from the top retrieved documents, compute DCG sum.
def ndcg_helper(list_gains):
    # compute numerator
    sum = 0
    for i in range(len(list_gains)):
        if i == 0:
            sum += list_gains[i]
        else:
            sum += list_gains[i]/math.log(i,2)

    return sum


# qID: query ID in the test set relevance file
# retrieved_docIDs: list of retrieved document IDs (in the test set) corresponding to the qID, in the order of retrieval
# test_set_qrel_path: string containing the full file path to the test set query relevance judgment file
# NDCG is cutoff at len(retrieved_docIDs)
def ndcg(qID, retrieved_docIDs, test_set_qrel_path):
    fid = file_open(test_set_qrel_path, 'r')
    # Compute maximum
    line = fid.readline()
    all_gains = []
    n = len(retrieved_docIDs) # cutoff number
    retrieved_inds = range(n) # array index for the retrieved docs
    retrieved_gains = [0]*n # gains corresponding to the documents retrieved
    while line:
        tokens = line.split()
        # Skip if not the qID we are looking for
        if qID != tokens[0]:
            continue
        # Otherwise continue processing.
        # Put this in the list containing all gains (for computation of max DCG later)
        all_gains.append(tokens[2])
        # Find index of the document in retrieved_docIDs if it's there
        for ind in retrieved_inds:
            if retrieved_docIDs[ind] == tokens[1]:
                retrieved_gains[ind] = tokens[2]
                break # shouldn't contain any other matches in retrieved_docIDs

    # Compute max DCG
    all_gains.sort(reverse=True)
    denom = ndcg_helper(all_gains)
    numerator = ndcg_helper(retrieved_gains)

    return denom/numerator